{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f698b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import gzip\n",
    "import struct\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "def load_images(filename):\n",
    "    with gzip.open(filename,'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',f.read(16)) # type: ignore\n",
    "        data = np.frombuffer(f.read(),dtype=np.uint8)\n",
    "        images = data.reshape(num,rows, cols)\n",
    "    return images\n",
    "\n",
    "def load_labels(filename):\n",
    "    with gzip.open(filename,'rb')as f:\n",
    "        magic, num = struct.unpack(\">II\",f.read(8))\n",
    "        labels = np.frombuffer(f.read(),dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "train_images = load_images('./data/MNIST/raw/train-images-idx3-ubyte.gz')\n",
    "train_labels = load_labels('./data/MNIST/raw/train-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "train_images = train_images.astype(np.float32)/255.0\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0],-1)\n",
    "\n",
    "def one_hot(labels, num_classes = 10):\n",
    "    result = np.zeros((labels.size, num_classes))\n",
    "    result[np.arange(labels.size),labels] = 1\n",
    "    return result\n",
    "\n",
    "train_labels_oh = one_hot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Initialization\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "\n",
    "np.random.seed(0)\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "\n",
    "# Actication Functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "# Forward propagation\n",
    "def forward(x):\n",
    "    z1 = np.dot(x, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "\n",
    "#Loss function\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    eps = 1e-12\n",
    "    y_pred = np.clip(y_pred, eps, 1. - eps)\n",
    "    N = y_true.shape[0]\n",
    "    return -np.sum(y_true * np.log(y_pred)) / N\n",
    "\n",
    "\n",
    "# Backward Propagation\n",
    "def backward(x, y_true, z1, a1, z2, a2, lr=0.01):\n",
    "    global W1, b1, W2, b2\n",
    "    m = x.shape[0]\n",
    "\n",
    "    # Output layer gradients\n",
    "    dz2 = (a2 - y_true) / m\n",
    "    dW2 = np.dot(a1.T, dz2)\n",
    "    db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "\n",
    "    # Hidden layer gradients\n",
    "    da1 = np.dot(dz2, W2.T)\n",
    "    dz1 = da1 * (z1 > 0)\n",
    "    dW1 = np.dot(x.T, dz1)\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "\n",
    "    # Gradient descent parameter update\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be3a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 60\n",
    "batch_size = 256\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    permutation = np.random.permutation(train_images.shape[0])\n",
    "    X_shuffled = train_images[permutation]\n",
    "    Y_shuffled = train_labels_oh[permutation]\n",
    "\n",
    "    epoch_loss = 0\n",
    "    batches = 0\n",
    "\n",
    "    for i in range(0, X_shuffled.shape[0], batch_size):\n",
    "        x_batch = X_shuffled[i:i + batch_size]\n",
    "        y_batch = Y_shuffled[i:i + batch_size]\n",
    "\n",
    "        z1, a1, z2, a2 = forward(x_batch)\n",
    "        loss = cross_entropy_loss(y_batch, a2)\n",
    "        backward(x_batch, y_batch, z1, a1, z2, a2)\n",
    "\n",
    "        epoch_loss += loss\n",
    "        batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / batches\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1:02d} | Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def accuracy(x, y_true):\n",
    "    _, _, _, a2 = forward(x)\n",
    "    y_pred = np.argmax(a2, axis=1)\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    return np.mean(y_pred == y_true_labels)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy(train_images[:10000], train_labels_oh[:10000]))\n",
    "\n",
    "# Plot training loss curve\n",
    "plt.plot(range(1, epochs + 1), loss_history, marker='o')\n",
    "plt.title('Loss Curve (Training)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea71d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Phase\n",
    "test_images = load_images('./data/MNIST/raw/t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_labels('./data/MNIST/raw/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "test_images = test_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.reshape(test_images.shape[0], -1)\n",
    "test_labels_oh = one_hot(test_labels)\n",
    "\n",
    "test_acc = accuracy(test_images, test_labels_oh)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
